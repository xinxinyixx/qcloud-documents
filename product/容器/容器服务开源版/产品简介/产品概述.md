## 产品简介
容器服务开源版（Tencent Kubernetes Engine Stack，TKE Stack） 是一款集强壮性和易用性于一体的开源容器编排引擎。容器服务开源版基于 Docker 和 Kubernetes 实现了容器应用的全生命周期管理能力。您可以使用与公有云容器服务相同的控制台界面，方便的管理云上云下不同基础设施上的业务和资源，灵活、敏捷、高效地构建和发布应用程序。



## 产品功能

### 异构部署
- 适配由 x86 或 arm64 服务器组建的异构容器集群，为国产化信息安全建设保驾护航。
- 一键安装 GPU 和 Nvidia 相关依赖，统一管理由不同型号 GPU 服务器组建的异构容器计算集群，无需关心繁琐的部署运维工作，专注 AI 业务本身。


### 混合云多集群管理
- 可以在控制台创建或接入云上云下不同基础设施上的 Kubernetes 集群，实现混合云场景下的多集群统一管理，提供故障迁移能力。
- 在集群命名空间上层抽象出业务层级，方便您根据企业需求灵活地实现应用的跨集群部署和统一管理。


### 服务管理
- 兼容 Kubernetes 原生服务访问模式，支持集群内服务互访及被集群外其他负载访问。
- 支持服务容器化封装，镜像仓库统一管理，提升了业务的迁移和发布效率。


### 拓展组件支持
- **TAPP 插件**：是基于 Kubernetes CRD 实现的通用类型的工作负载，提供了应用的灰度发布、原地升级、Pod 内部分容器更新及故障不调度等功能，支撑您沿用类似虚拟机的使用和管理习惯。
- **Galaxy 插件**：是 Kubernetes 的网络项目，旨在为 Pod 提供通用 Overlay 和高性能的 Underlay 网络。共支持四种网模式，可以为工作负载单独配置指定的网络模式，拓展了容器应用场景，满足复杂应用容器化的特殊需求。
- **GPU Manager 插件**：提供一个 All-in-One 的 GPU 管理器，基于 Kubernetes DevicePlugin 插件系统实现。该管理器提供了多容器共享 GPU 资源、GPU 指标查询、 容器运行前 GPU 相关设备准备、智能感知 GPU 拓扑结构、RDMA 网络高速网络等能力。帮助您提升 GPU 资源利用率，缩短 AI 任务训练时间。
- **LBCF 插件**：是部署在 Kubernetes 内的通用负载均衡控制面框架，旨在降低容器对接负载均衡的实现难度，并提供强大的扩展能力以满足业务方在使用负载均衡时的个性化需求。例如，多环境负载均衡共享、Pod 独立绑定，自定义灰度升级策略等。
- **CronHPA 插件**：基于 crontab 方案，支持定期自动扩缩容工作负载（支持扩展子资源的负载。例如，Deployment、Statefulset ）的副本数量。满足业务的潮汐效应，降低资源使用成本。
- **CSIOperator 插件**：通过配置项简化配置 CSI 的流程，帮助您在 Kubernetes 集群快速对接第三方存储，例如 Ceph。
- **LogCollector 插件**：是集群内日志收集工具，可以将集群内服务或集群节点特定路径文件的日志发送至 Kafka 的指定 topic 或日志服务 CLS 的指定日志主题。
- **PersistentEvent 插件**：提供 Kubernetes 集群事件持久化功能，支持将集群事件实时导出到配置的存储端。

  

### 多租户管理
- 提供基于角色的多租户统一认证与权限管理。权限等级由高至低分为平台管理、业务、集群命名空间三个层级，充分保障各层级间不同角色间资源共享且互相隔离。
- 支持基于角色的业务管理。业务可以共享平台的基础设施资源，并根据业务需求进行资源配额限制。
- 支持对接企业基于 LDAP/OIDC 协议的认证系统，以实现企业租户身份的统一认证。



### 镜像仓库管理
- 支持创建私有镜像仓库。
- 支持管理多个镜像命名空间。
- 支持使用镜像仓库查看、上传及下载镜像。



### 运维管理
- 提供集群、节点、工作负载、Pod、Container 五个粒度的监控数据收集和展示功能，助您实时掌握资源使用状况，轻松定位问题。
- 支持自定义告警策略、设置告警接收人、告警接收组和告警通知模板，助您合理配置告警规则，降低业务风险。
- 支持集群事件和日志与第三方存储系统集成，方便您进行系统和业务的相关分析。



## 使用流程

您只需要执行以下步骤即可运行应用程序：
1. 安装容器服务开源版控制台
2. 创建或导入集群 
3. 创建服务/业务
4. 运行服务/业务


